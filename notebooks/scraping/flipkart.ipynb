{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#  Scraping sur Flipkart\n",
    "\n",
    "Ce notebook a pour objectif de scraper des informations sur Flipkart pour différentes catégories de produits (graphics_cards, laptops, monitors, smart_watches).\n",
    "\n",
    "**Fonctionnalités :**\n",
    "- Récupération des détails d'un produit (spécifications, ratings, reviews, etc.).\n",
    "- Extraction des informations depuis une page de résultats.\n",
    "- Sauvegarde des données extraites dans des fichiers CSV organisés par catégorie.\n",
    "\n",
    "**Bibliothèques utilisées :**\n",
    "- `os`, `time`, `random` pour la gestion du système et des délais.\n",
    "- `requests` pour envoyer des requêtes HTTP.\n",
    "- `BeautifulSoup` (via `bs4`) pour parser le HTML.\n",
    "- `pandas` pour la manipulation et la sauvegarde des données.\n",
    "- `datetime` pour la gestion des dates.\n",
    "- `re` pour les expressions régulières.\n"
   ],
   "id": "69d3665640a05a43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n"
   ],
   "id": "8cb7a322ac5e577a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Constants et Headers\n",
    "\n",
    "Nous définissons ici quelques constantes essentielles :\n",
    "- **USER_AGENTS** : Une liste de User-Agent pour simuler des requêtes provenant de différents navigateurs.\n",
    "- **DEFAULT_HEADERS** : Les en-têtes HTTP utilisés pour nos requêtes, incluant un User-Agent choisi aléatoirement.\n"
   ],
   "id": "bee2903ba9688f99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Liste de User-Agent pour varier les requêtes\n",
    "USER_AGENTS = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Mozilla/5.0 (iPhone; CPU iPhone OS 14_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1',\n",
    "]\n",
    "\n",
    "DEFAULT_HEADERS = {\n",
    "    'User-Agent': random.choice(USER_AGENTS),\n",
    "    'Accept-Language': 'en-US, en;q=0.5'\n",
    "}\n"
   ],
   "id": "9161021186120c3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fonctions Utilitaires\n",
    "\n",
    "Ces fonctions facilitent l'extraction et le traitement des données :\n",
    "- **get_text_or_default** : Extrait le texte d'un élément BeautifulSoup ou renvoie une valeur par défaut.\n",
    "- **wait_random** : Introduit une attente aléatoire pour éviter d'être détecté.\n",
    "- **extract_specifications** : Extrait les spécifications d'un produit à partir du HTML.\n"
   ],
   "id": "de66d226e0e4c96e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_text_or_default(element, default=\"Data not available\"):\n",
    "    \"\"\"Extrait le texte d'un élément BeautifulSoup ou renvoie une valeur par défaut.\"\"\"\n",
    "    return element.text.strip() if element else default\n",
    "\n",
    "def wait_random(min_time=3, max_time=7):\n",
    "    \"\"\"Attend un nombre de secondes aléatoire pour éviter la détection.\"\"\"\n",
    "    delay = random.randint(min_time, max_time)\n",
    "    print(f\"Waiting {delay} seconds...\")\n",
    "    time.sleep(delay)\n",
    "\n",
    "def extract_specifications(soup):\n",
    "    \"\"\"Extrait les spécifications de la section de détails d'un produit.\"\"\"\n",
    "    specifications = {}\n",
    "    spec_sections = soup.find_all('div', class_='GNDEQ-')\n",
    "\n",
    "    for section in spec_sections:\n",
    "        section_title = section.find('div', class_='_4BJ2V+')\n",
    "        if not section_title:\n",
    "            continue\n",
    "        section_title = section_title.text.strip()\n",
    "\n",
    "        spec_rows = section.find_all('tr', class_='WJdYP6 row')\n",
    "        for row in spec_rows:\n",
    "            key_element = row.find('td', class_='+fFi1w col col-3-12')\n",
    "            value_element = row.find('td', class_='Izz52n col col-9-12')\n",
    "\n",
    "            if key_element and value_element:\n",
    "                key = key_element.text.strip()\n",
    "                value = value_element.text.strip()\n",
    "                specifications[key] = value\n",
    "\n",
    "    return specifications\n"
   ],
   "id": "6b93c00d3112630e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scraping des Détails d'un Produit\n",
    "\n",
    "La fonction `scrape_flipkart_product` effectue les opérations suivantes :\n",
    "- Envoie une requête HTTP pour obtenir la page du produit.\n",
    "- Parse le HTML et extrait les spécifications via `extract_specifications`.\n",
    "- Récupère la note (rating) et le nombre d'avis (reviews) à l'aide d'expressions régulières.\n",
    "- Retourne un dictionnaire regroupant ces informations.\n"
   ],
   "id": "2182f2999180a09a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def scrape_flipkart_product(product_url):\n",
    "    \"\"\"Scrape les informations détaillées d'un produit (spécifications, rating, reviews).\"\"\"\n",
    "    headers = DEFAULT_HEADERS\n",
    "    try:\n",
    "        response = requests.get(product_url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        specifications = extract_specifications(soup)\n",
    "\n",
    "        rating_element = soup.find('div', class_='_3LWZlK')\n",
    "        rating = get_text_or_default(rating_element)\n",
    "\n",
    "        reviews_element = soup.find('span', class_='_2_R_DZ')\n",
    "        reviews_text = get_text_or_default(reviews_element)\n",
    "\n",
    "        reviews_match = re.search(r'\\d+', reviews_text.replace(',', ''))\n",
    "        reviews = reviews_match.group() if reviews_match else \"Data not available\"\n",
    "\n",
    "        return {\n",
    "            \"rating\": rating,\n",
    "            \"reviews\": reviews,\n",
    "            **specifications,\n",
    "        }\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error occurred while scraping product {product_url}: {e}\")\n",
    "        return {\"rating\": \"Data not available\", \"reviews\": \"Data not available\"}\n"
   ],
   "id": "2092644b75c2c74d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scraping d'une Page de Résultats\n",
    "\n",
    "La fonction `scrape_flipkart_page` :\n",
    "- Envoie une requête pour obtenir une page de résultats d'une catégorie donnée.\n",
    "- Identifie les blocs produits et extrait pour chacun les informations telles que le titre, le prix, le rating, les reviews, l'image et l'URL du produit.\n",
    "- Pour chaque produit, elle peut également appeler `scrape_flipkart_product` afin d'obtenir des spécifications détaillées.\n"
   ],
   "id": "dd07663acd535789"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def scrape_flipkart_page(url, category_name):\n",
    "    headers = DEFAULT_HEADERS\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        product_blocks = soup.find_all('div', class_='cPHDOP col-12-12')\n",
    "        if not product_blocks:\n",
    "            print(\"No product blocks found on this page.\")\n",
    "            return []\n",
    "\n",
    "        scraped_items = []\n",
    "        collection_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        for product in product_blocks:\n",
    "            if category_name == \"graphics_cards\":\n",
    "                title_element = product.find('a', class_='wjcEIp')\n",
    "                price_element = product.find('div', class_='Nx9bqj')\n",
    "                rating_element = product.find('div', class_='XQDdHH')\n",
    "                reviews_element = product.find('span', class_='Wphh3N')\n",
    "                image_element = product.find('img', class_='DByuf4')\n",
    "                link_element = product.find('a', class_='VJA3rP')\n",
    "            elif category_name == \"laptops\":\n",
    "                title_element = product.find('div', class_='KzDlHZ')\n",
    "                price_element = product.find('div', class_='Nx9bqj _4b5DiR')\n",
    "                rating_element = product.find('div', class_='XQDdHH')\n",
    "                reviews_element = product.find('span', class_='Wphh3N')\n",
    "                image_element = product.find('img', class_='DByuf4')\n",
    "                link_element = product.find('a', class_='CGtC98')\n",
    "            elif category_name == \"monitors\":\n",
    "                title_element = product.find('div', class_='KzDlHZ')\n",
    "                price_element = product.find('div', class_='Nx9bqj _4b5DiR')\n",
    "                rating_element = product.find('div', class_='XQDdHH')\n",
    "                reviews_element = product.find('span', class_='Wphh3N')\n",
    "                image_element = product.find('img', class_='DByuf4')\n",
    "                link_element = product.find('a', class_='CGtC98')\n",
    "            elif category_name == \"smart_watches\":\n",
    "                title_element = product.find('a', class_='WKTcLC')\n",
    "                price_element = product.find('div', class_='Nx9bqj')\n",
    "                rating_element = product.find('div', class_='XQDdHH')\n",
    "                reviews_element = product.find('span', class_='Wphh3N')\n",
    "                image_element = product.find('img', class_='_53J4C-')\n",
    "                link_element = product.find('a', class_='rPDeLR')\n",
    "\n",
    "            title = get_text_or_default(title_element)\n",
    "            price = get_text_or_default(price_element)\n",
    "            rating = get_text_or_default(rating_element)\n",
    "            reviews = get_text_or_default(reviews_element)\n",
    "            image_url = image_element['src'] if image_element else \"Image not available\"\n",
    "            product_url = f\"https://www.flipkart.com{link_element['href']}\" if link_element else \"URL not available\"\n",
    "\n",
    "            specifications = scrape_flipkart_product(product_url) if product_url != \"URL not available\" else {}\n",
    "\n",
    "            scraped_items.append({\n",
    "                \"title\": title,\n",
    "                \"price\": price,\n",
    "                \"rating\": rating,\n",
    "                \"reviews\": reviews,\n",
    "                \"image_url\": image_url,\n",
    "                \"product_url\": product_url,\n",
    "                \"collection_date\": collection_date,\n",
    "                **specifications,\n",
    "            })\n",
    "\n",
    "        return scraped_items\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error occurred while scraping {url}: {e}\")\n",
    "        return []\n"
   ],
   "id": "b46ebd0761f3d883"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Gestion de la Numérotation des Scrapes\n",
    "\n",
    "La fonction `get_next_scrape_number` permet de déterminer le prochain numéro de scrape afin d'éviter d'écraser des fichiers existants lors de la sauvegarde.\n"
   ],
   "id": "a527509094c1dd24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_next_scrape_number(output_dir, category_name):\n",
    "    \"\"\"Détermine le prochain numéro de scrape pour un dossier donné.\"\"\"\n",
    "    scrape_number = 1\n",
    "    for filename in os.listdir(output_dir):\n",
    "        if filename.startswith(f\"{category_name}_\") and filename.endswith(\".csv\"):\n",
    "            try:\n",
    "                # Extraction du numéro de scrape à partir du nom du fichier\n",
    "                current_number = int(filename.split('_scrape')[-1].split('.')[0])\n",
    "                if current_number >= scrape_number:\n",
    "                    scrape_number = current_number + 1\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return scrape_number\n"
   ],
   "id": "4e54e6f2b530d82e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fonction Principale de Scraping pour Flipkart\n",
    "\n",
    "La fonction `scrape_flipkart` orchestre le scraping pour une catégorie donnée :\n",
    "- Elle parcourt le nombre de pages défini.\n",
    "- Pour chaque page, elle appelle `scrape_flipkart_page` afin d'extraire les produits.\n",
    "- Elle accumule les résultats, puis sauvegarde les données dans un fichier CSV dans un dossier dédié à la catégorie.\n"
   ],
   "id": "eb57b7b8bcbdb58c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def scrape_flipkart(category_url, num_pages, category_name, output_dir=\"data/raw/flipkart\"):\n",
    "    aggregated_results = []\n",
    "    for page in range(1, num_pages + 1):\n",
    "        print(f\"Scraping page {page}...\")\n",
    "        page_url = f\"{category_url}&page={page}\"\n",
    "        page_results = scrape_flipkart_page(page_url, category_name)\n",
    "\n",
    "        if not page_results:\n",
    "            print(\"No more products found. Stopping.\")\n",
    "            break\n",
    "\n",
    "        aggregated_results.extend(page_results)\n",
    "        wait_random()\n",
    "\n",
    "    if aggregated_results:\n",
    "        today = datetime.today()\n",
    "        formatted_date = today.strftime(\"%Y_%m_%d\")\n",
    "\n",
    "        # Création du dossier spécifique à la catégorie\n",
    "        category_directory = os.path.join(output_dir, category_name)\n",
    "        os.makedirs(category_directory, exist_ok=True)\n",
    "\n",
    "        # Détermination du prochain numéro de scrape\n",
    "        scrape_number = get_next_scrape_number(category_directory, category_name)\n",
    "\n",
    "        filename = f\"{category_name}_{formatted_date}_scrape{scrape_number}.csv\"\n",
    "        output_path = os.path.join(category_directory, filename)\n",
    "\n",
    "        df = pd.DataFrame(aggregated_results)\n",
    "        df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Data saved to {output_path}\")\n",
    "    else:\n",
    "        print(\"No data scraped.\")\n",
    "\n",
    "    return aggregated_results\n"
   ],
   "id": "e776f603d0c9bb72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Script Principal\n",
    "\n",
    "Nous définissons ici un dictionnaire `categories` qui associe à chaque catégorie son URL de base et le nombre de pages à scraper.\n",
    "Ensuite, nous parcourons chaque catégorie et appelons la fonction `scrape_flipkart` pour récupérer et sauvegarder les données.\n"
   ],
   "id": "21c95b0de60edae1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:35:06.399136Z",
     "start_time": "2025-02-08T18:35:05.775934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    categories = {\n",
    "        \"graphics_cards\": {\n",
    "            \"url\": \"https://www.flipkart.com/gaming-components/graphic-cards/pr?sid=4rr,tin,6zn&q=graphics+card&otracker=categorytree\",\n",
    "            \"num_pages\": 0  # Modifier le nombre de pages souhaité\n",
    "        },\n",
    "        \"laptops\": {\n",
    "            \"url\": \"https://www.flipkart.com/laptops/pr?sid=6bo,b5g&q=laptop&otracker=categorytree\",\n",
    "            \"num_pages\": 0  # Modifier le nombre de pages souhaité\n",
    "        },\n",
    "        \"monitors\": {\n",
    "            \"url\": \"https://www.flipkart.com/search?q=monitor&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\",\n",
    "            \"num_pages\": 13\n",
    "        },\n",
    "        \"smart_watches\": {\n",
    "            \"url\": \"https://www.flipkart.com/wearable-smart-devices/smart-watches/pr?sid=ajy,buh&q=smart+watches&otracker=categorytree\",\n",
    "            \"num_pages\": 13\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for category_name, config in categories.items():\n",
    "        print(f\"Scraping {category_name}...\")\n",
    "        scrape_flipkart(config[\"url\"], config[\"num_pages\"], category_name)\n"
   ],
   "id": "3fc795e3d5450e81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping graphics_cards...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scrape_flipkart' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 23\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m category_name, config \u001B[38;5;129;01min\u001B[39;00m categories\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mScraping \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcategory_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 23\u001B[0m     \u001B[43mscrape_flipkart\u001B[49m(config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124murl\u001B[39m\u001B[38;5;124m\"\u001B[39m], config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_pages\u001B[39m\u001B[38;5;124m\"\u001B[39m], category_name)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'scrape_flipkart' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##  interprétations des résultats.\n",
    "\n",
    "Ce notebook vous permet de :\n",
    "- **Scraper** les données de Flipkart pour différentes catégories de produits.\n",
    "- **Extraire** des informations détaillées telles que les spécifications, ratings et reviews.\n",
    "- **Sauvegarder** les résultats dans des fichiers CSV organisés par catégorie.\n",
    "\n",
    "\n"
   ],
   "id": "432bfd12ad0ca50c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:37:42.602137Z",
     "start_time": "2025-02-08T18:37:42.553410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Définir le chemin vers le fichier CSV nettoyé\n",
    "csv_file_path = Path(r'C:\\Users\\AdMin\\Desktop\\ecommerce_scraper\\data\\cleaned\\flipkart\\laptops\\laptops_2025_01_29_scrape1_cleaned.csv')\n",
    "\n",
    "df_cleaned = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Set the option to display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Display all rows of the DataFrame\n",
    "df_cleaned.head(10)"
   ],
   "id": "633b8006855d67a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Title    Price   RAM  \\\n",
       "0  SAMSUNG Galaxy Book4 Metal i3 13th1315U - (8 G...  499.875   8.0   \n",
       "1  HP 15 (2024) 3 Quad7320U - (8 GB/512 GB /dows ...  424.875   8.0   \n",
       "2  ASUS Vivobook 15 i3 12th1215U - (8 GB/512 GB /...  399.875   8.0   \n",
       "3  HP 15s i3 12th1215U - (8 GB/512 GB /dows 11 Ho...  434.875   8.0   \n",
       "4  MSI in 1512th12450H - (16 GB/512 GB /dows 11 H...  649.875  16.0   \n",
       "5  Acer Aspire 713th13420H - (16 GB/512 GB /dows ...  724.875  16.0   \n",
       "6  ASUS Vivobook 15, with Backlit , i3 12th1215U ...  399.875   8.0   \n",
       "7  HP13th1334U - (16 GB/512 GB /dows 11 Home) 15f...  699.875  16.0   \n",
       "8  ASUS Vivobook 15 i3 12th1215U - (16 GB/512 GB ...  437.375  16.0   \n",
       "9  ASUS Vivobook 15 i3 12th1215U - (16 GB/512 GB ...  437.375  16.0   \n",
       "\n",
       "                 CPU                  Model    Brand  \\\n",
       "0            Core i3         NP750XGJ-LG4IN  SAMSUNG   \n",
       "1  Ryzen 3 Quad Core            15-fc0154AU       HP   \n",
       "2            Core i3        X1504ZA-NJ322WS     ASUS   \n",
       "3            Core i3           15s-fy5003TU       HP   \n",
       "4            Core i5  Thin 15 B12UCX-1695IN      MSI   \n",
       "5            Core i5               A715-79G     Acer   \n",
       "6            Core i3            Vivobook 15     ASUS   \n",
       "7            Core i5            15-fd0315TU       HP   \n",
       "8            Core i3        X1504ZA-NJ342WS     ASUS   \n",
       "9            Core i3        X1502ZA-EJ993WS     ASUS   \n",
       "\n",
       "                                               GPU           Screen Size  \\\n",
       "0                         Intel Integrated Iris Xe  39.62 cm (15.6 Inch)   \n",
       "1                                   AMD Radeon AMD  39.62 cm (15.6 Inch)   \n",
       "2                             Intel Integrated UHD  39.62 cm (15.6 Inch)   \n",
       "3                             Intel Integrated UHD  39.62 cm (15.6 inch)   \n",
       "4                          NVIDIA GeForce RTX 2050  39.62 cm (15.6 Inch)   \n",
       "5                          NVIDIA GeForce RTX 2050  39.62 cm (15.6 Inch)   \n",
       "6  Intel Integrated Integrated Intel® UHD Graphics  39.62 cm (15.6 Inch)   \n",
       "7                         Intel Integrated Iris Xe  39.62 cm (15.6 Inch)   \n",
       "8                             Intel Integrated UHD  39.62 cm (15.6 Inch)   \n",
       "9                             Intel Integrated UHD  39.62 cm (15.6 Inch)   \n",
       "\n",
       "   Storage Collection Date  \n",
       "0    512.0      2025-01-29  \n",
       "1    512.0      2025-01-29  \n",
       "2    512.0      2025-01-29  \n",
       "3    512.0      2025-01-29  \n",
       "4    512.0      2025-01-29  \n",
       "5    512.0      2025-01-29  \n",
       "6    512.0      2025-01-29  \n",
       "7    512.0      2025-01-29  \n",
       "8    512.0      2025-01-29  \n",
       "9    512.0      2025-01-29  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>RAM</th>\n",
       "      <th>CPU</th>\n",
       "      <th>Model</th>\n",
       "      <th>Brand</th>\n",
       "      <th>GPU</th>\n",
       "      <th>Screen Size</th>\n",
       "      <th>Storage</th>\n",
       "      <th>Collection Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAMSUNG Galaxy Book4 Metal i3 13th1315U - (8 G...</td>\n",
       "      <td>499.875</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Core i3</td>\n",
       "      <td>NP750XGJ-LG4IN</td>\n",
       "      <td>SAMSUNG</td>\n",
       "      <td>Intel Integrated Iris Xe</td>\n",
       "      <td>39.62 cm (15.6 Inch)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2025-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP 15 (2024) 3 Quad7320U - (8 GB/512 GB /dows ...</td>\n",
       "      <td>424.875</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Ryzen 3 Quad Core</td>\n",
       "      <td>15-fc0154AU</td>\n",
       "      <td>HP</td>\n",
       "      <td>AMD Radeon AMD</td>\n",
       "      <td>39.62 cm (15.6 Inch)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2025-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Vivobook 15 i3 12th1215U - (8 GB/512 GB /...</td>\n",
       "      <td>399.875</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Core i3</td>\n",
       "      <td>X1504ZA-NJ322WS</td>\n",
       "      <td>ASUS</td>\n",
       "      <td>Intel Integrated UHD</td>\n",
       "      <td>39.62 cm (15.6 Inch)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2025-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 15s i3 12th1215U - (8 GB/512 GB /dows 11 Ho...</td>\n",
       "      <td>434.875</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Core i3</td>\n",
       "      <td>15s-fy5003TU</td>\n",
       "      <td>HP</td>\n",
       "      <td>Intel Integrated UHD</td>\n",
       "      <td>39.62 cm (15.6 inch)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2025-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSI in 1512th12450H - (16 GB/512 GB /dows 11 H...</td>\n",
       "      <td>649.875</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Core i5</td>\n",
       "      <td>Thin 15 B12UCX-1695IN</td>\n",
       "      <td>MSI</td>\n",
       "      <td>NVIDIA GeForce RTX 2050</td>\n",
       "      <td>39.62 cm (15.6 Inch)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2025-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acer Aspire 713th13420H - (16 GB/512 GB /dows ...</td>\n",
       "      <td>724.875</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Core i5</td>\n",
       "      <td>A715-79G</td>\n",
       "      <td>Acer</td>\n",
       "      <td>NVIDIA GeForce RTX 2050</td>\n",
       "      <td>39.62 cm (15.6 Inch)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2025-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS Vivobook 15, with Backlit , i3 12th1215U ...</td>\n",
       "      <td>399.875</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Core i3</td>\n",
       "      <td>Vivobook 15</td>\n",
       "      <td>ASUS</td>\n",
       "      <td>Intel Integrated Integrated Intel® UHD Graphics</td>\n",
       "      <td>39.62 cm (15.6 Inch)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2025-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP13th1334U - (16 GB/512 GB /dows 11 Home) 15f...</td>\n",
       "      <td>699.875</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Core i5</td>\n",
       "      <td>15-fd0315TU</td>\n",
       "      <td>HP</td>\n",
       "      <td>Intel Integrated Iris Xe</td>\n",
       "      <td>39.62 cm (15.6 Inch)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2025-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS Vivobook 15 i3 12th1215U - (16 GB/512 GB ...</td>\n",
       "      <td>437.375</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Core i3</td>\n",
       "      <td>X1504ZA-NJ342WS</td>\n",
       "      <td>ASUS</td>\n",
       "      <td>Intel Integrated UHD</td>\n",
       "      <td>39.62 cm (15.6 Inch)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2025-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS Vivobook 15 i3 12th1215U - (16 GB/512 GB ...</td>\n",
       "      <td>437.375</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Core i3</td>\n",
       "      <td>X1502ZA-EJ993WS</td>\n",
       "      <td>ASUS</td>\n",
       "      <td>Intel Integrated UHD</td>\n",
       "      <td>39.62 cm (15.6 Inch)</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2025-01-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
