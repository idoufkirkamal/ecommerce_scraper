{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse et Visualisation des Données de Monitors\n",
    "\n",
    "Ce Notebook a pour objectif d'analyser et de visualiser les données concernant les monitors collectées sur les plateformes **eBay** et **Flipkart**.\n",
    "\n",
    "Les étapes réalisées incluent :\n",
    "\n",
    "- **Importation des librairies** : Manipulation des données, création de graphiques, gestion des chemins et journalisation.\n",
    "- **Configuration des chemins** : Définition des répertoires du projet pour les données nettoyées et les résultats.\n",
    "- **Chargement des données nettoyées** : Lecture et préparation des fichiers CSV pour la catégorie *monitors*.\n",
    "- **Filtrage des produits cross-plateformes** : Identification des monitors ayant des spécifications identiques sur les deux plateformes.\n",
    "- **Analyse et visualisation des différences de prix** : Agrégation des données et génération de graphiques pour observer les tendances de prix.\n",
    "\n",
    "Chaque fonction est expliquée en détail ci-dessous.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des Librairies et Configuration du Logging\n",
    "\n",
    "Dans cette section, nous importons les bibliothèques nécessaires pour :\n",
    "- La manipulation de données avec **pandas**.\n",
    "- La création de graphiques avec **matplotlib** et **seaborn**.\n",
    "- La gestion des chemins avec **pathlib**.\n",
    "- Le traitement des chaînes de caractères avec **re**.\n",
    "- La journalisation des opérations avec **logging**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration des Chemins du Projet\n",
    "\n",
    "Ici, nous définissons les chemins essentiels du projet :\n",
    "- `PROJECT_ROOT` : La racine du projet.\n",
    "- `CLEANED_DATA_PATH` : Le dossier contenant les données nettoyées.\n",
    "- `RESULTS_PATH` : Le dossier où seront sauvegardés les résultats (graphiques générés).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[2]\n",
    "CLEANED_DATA_PATH = PROJECT_ROOT / 'data' / 'cleaned'\n",
    "RESULTS_PATH = PROJECT_ROOT / 'results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des Données Nettoyées pour les Monitors\n",
    "\n",
    "La fonction `load_cleaned_data` charge les fichiers CSV nettoyés pour la catégorie **monitors** provenant des plateformes *eBay* et *Flipkart*.  \n",
    "Pour chaque fichier, elle effectue les opérations suivantes :\n",
    "- **Standardisation des noms de colonnes** : Conversion en minuscules et remplacement des espaces par des underscores.\n",
    "- **Validation des colonnes requises** : Vérification de la présence des colonnes essentielles (par exemple, *title*, *price*, *screen_size_in*, etc.).\n",
    "- **Ajout de l’identifiant de plateforme**.\n",
    "- **Normalisation des champs** : Application des fonctions `normalize_brand` et `normalize_aspect_ratio` ainsi que la conversion de la taille de l’écran en nombre entier.\n",
    "- **Traitement de la date de collecte** : Conversion de la colonne `collection_date` en date.\n",
    "  \n",
    "Les DataFrames obtenus sont ensuite concaténés pour former un DataFrame global.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cleaned_data():\n",
    "    \"\"\"Load cleaned data for monitors from eBay and Flipkart\"\"\"\n",
    "    platforms = ['ebay', 'flipkart']\n",
    "    dfs = []\n",
    "    \n",
    "    required_columns = {\n",
    "        'title', 'price', 'screen_size_in', 'aspect_ratio', \n",
    "        'refresh_rate_hz', 'response_time_ms', 'brand', 'collection_date'\n",
    "    }\n",
    "    \n",
    "    for platform in platforms:\n",
    "        data_dir = CLEANED_DATA_PATH / platform / 'monitors'\n",
    "        if not data_dir.exists():\n",
    "            logger.warning(f\"Missing data directory: {data_dir}\")\n",
    "            continue\n",
    "            \n",
    "        for file in data_dir.glob('*.csv'):\n",
    "            try:\n",
    "                df = pd.read_csv(file)\n",
    "                df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns]\n",
    "                \n",
    "                # Validate columns\n",
    "                missing_cols = required_columns - set(df.columns)\n",
    "                if missing_cols:\n",
    "                    logger.warning(f\"Missing columns in {file}: {missing_cols}\")\n",
    "                    continue\n",
    "                \n",
    "                # Add platform identifier\n",
    "                df['platform'] = platform\n",
    "                \n",
    "                # Normalize key fields\n",
    "                df['brand'] = df['brand'].apply(normalize_brand)\n",
    "                df['aspect_ratio'] = df['aspect_ratio'].apply(normalize_aspect_ratio)\n",
    "                df['screen_size_in'] = df['screen_size_in'].apply(\n",
    "                    lambda x: round(float(x)) if pd.notnull(x) else None\n",
    "                )\n",
    "                \n",
    "                # Handle collection date\n",
    "                df['collection_date'] = pd.to_datetime(\n",
    "                    df['collection_date'], errors='coerce'\n",
    "                ).dt.date\n",
    "                \n",
    "                dfs.append(df)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error loading {file}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrage des Produits Cross-plateformes\n",
    "\n",
    "La fonction `filter_products_by_platforms` identifie les monitors présentant des spécifications identiques sur les deux plateformes.  \n",
    "Pour cela, elle :\n",
    "- Crée un identifiant unique (`product_id`) pour chaque produit en combinant plusieurs champs (brand, screen size, aspect ratio, refresh rate, response time).\n",
    "- Regroupe les produits par `product_id` et sélectionne ceux présents sur **eBay** et **Flipkart**.\n",
    "  \n",
    "Le DataFrame retourné contient uniquement les monitors disponibles sur les deux plateformes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_products_by_platforms(df: pd.DataFrame):\n",
    "    \"\"\"Find monitors with matching specifications across platforms\"\"\"\n",
    "    # Create a unique product identifier\n",
    "    df['product_id'] = (\n",
    "        df['brand'] + \"|\" + \n",
    "        df['screen_size_in'].astype(str) + \"|\" + \n",
    "        df['aspect_ratio'].astype(str) + \"|\" + \n",
    "        df['refresh_rate_hz'].astype(str) + \"|\" + \n",
    "        df['response_time_ms'].astype(str)\n",
    "    )\n",
    "    \n",
    "    # Find products present on both platforms\n",
    "    platform_groups = df.groupby('product_id')['platform'].unique()\n",
    "    cross_platform = platform_groups[platform_groups.apply(\n",
    "        lambda x: len(set(x) & {'ebay', 'flipkart'}) >= 2\n",
    "    )].index.tolist()\n",
    "    \n",
    "    return df[df['product_id'].isin(cross_platform)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse et Visualisation des Différences de Prix\n",
    "\n",
    "La fonction `analyze_price_differences` analyse les différences de prix pour les monitors identifiés sur les deux plateformes.  \n",
    "Les étapes réalisées comprennent :\n",
    "- **Agrégation** : Calcul du prix moyen par date de collecte pour chaque monitor et par plateforme.\n",
    "- **Visualisation** : Création d’un graphique en barres pour chaque produit, affichant l’évolution des prix au fil du temps.\n",
    "- **Sauvegarde** : Chaque graphique est enregistré dans le dossier `RESULTS_PATH / 'monitors'` avec un nom de fichier dérivé de l’identifiant du produit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_price_differences(filtered_df: pd.DataFrame):\n",
    "    \"\"\"Analyze and visualize price differences for matched monitors\"\"\"\n",
    "    if filtered_df.empty:\n",
    "        logger.info(\"No cross-platform monitors found for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Group by product_id and platform\n",
    "    grouped = filtered_df.groupby(['product_id', 'platform', 'collection_date'])['price'].mean().unstack(level='platform')\n",
    "    \n",
    "    # Generate bar plots for each monitor\n",
    "    for product_id, data in grouped.groupby(level=0):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Plot bar graph\n",
    "        data.plot(kind='bar', figsize=(12, 6))\n",
    "        \n",
    "        # Set title and labels\n",
    "        plt.title(f\"Price Trends for {product_id.replace('|', ' ')}\")\n",
    "        plt.xlabel(\"Collection Date\")\n",
    "        plt.ylabel(\"Price (USD)\")\n",
    "        \n",
    "        # Format x-axis dates\n",
    "        plt.xticks(range(len(data.index)), data.index.get_level_values('collection_date'), rotation=45, ha='right')\n",
    "        \n",
    "        # Add legend and grid\n",
    "        plt.legend(title='Platform')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        sanitized_title = re.sub(r\"[^\\w\\s]\", \"_\", product_id.replace(\"|\", \"_\"))\n",
    "        file_name = f\"Monitor_{sanitized_title}.png\"\n",
    "        # Assurez-vous que le dossier de destination existe\n",
    "        (RESULTS_PATH / 'monitors').mkdir(exist_ok=True, parents=True)\n",
    "        plt.savefig(RESULTS_PATH / 'monitors' / file_name)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exécution Principale\n",
    "\n",
    "La section suivante orchestre l'exécution complète du processus :\n",
    "1. **Création des dossiers de résultats** s'ils n'existent pas.\n",
    "2. **Chargement et traitement des données** via `load_cleaned_data()`.\n",
    "3. **Filtrage des produits cross-plateformes** avec `filter_products_by_platforms()`.\n",
    "4. **Analyse et visualisation des différences de prix** à l'aide de `analyze_price_differences()`.\n",
    "\n",
    "En cas d'erreur, un message détaillé est loggé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Créer les dossiers de résultats s'ils n'existent pas\n",
    "    RESULTS_PATH.mkdir(exist_ok=True)\n",
    "    (RESULTS_PATH / 'monitors').mkdir(exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Loading and processing monitor data...\")\n",
    "        df = load_cleaned_data()\n",
    "        \n",
    "        if df.empty:\n",
    "            logger.error(\"No cleaned data found. Check data/cleaned directories.\")\n",
    "            exit(1)\n",
    "            \n",
    "        logger.info(f\"Loaded {len(df)} records from cleaned data\")\n",
    "        \n",
    "        filtered_df = filter_products_by_platforms(df)\n",
    "        logger.info(f\"Found {len(filtered_df)} cross-platform monitor entries\")\n",
    "        \n",
    "        analyze_price_differences(filtered_df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Critical error: {str(e)}\", exc_info=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
