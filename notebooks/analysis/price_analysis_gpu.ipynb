{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse et Visualisation des Données des Cartes Graphiques\n",
    "\n",
    "Ce notebook a pour objectif d'analyser et de visualiser les données relatives aux cartes graphiques collectées sur plusieurs plateformes (eBay, Flipkart, Ubuy). \n",
    "\n",
    "Les étapes réalisées incluent :\n",
    "\n",
    "- **Importation des bibliothèques** : Manipulation des données, visualisation et gestion des chemins.\n",
    "- **Configuration des chemins** : Définition des répertoires du projet pour les données nettoyées et les résultats.\n",
    "- **Chargement des données nettoyées** : Lecture et préparation des fichiers CSV.\n",
    "- **Filtrage des produits** : Identification des produits disponibles sur plusieurs plateformes.\n",
    "- **Analyse et visualisation des tendances de prix** : Agrégation des données et génération de graphiques.\n",
    "\n",
    "Chaque fonction utilisée est expliquée en détail dans la suite du notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des Librairies\n",
    "\n",
    "Dans cette section, nous importons les bibliothèques nécessaires pour :\n",
    "\n",
    "- La manipulation de données avec **pandas**.\n",
    "- La création de graphiques avec **matplotlib** et **seaborn**.\n",
    "- La gestion des chemins avec **os** et **pathlib**.\n",
    "- Le traitement des expressions régulières avec **re**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration des Chemins du Projet\n",
    "\n",
    "Nous définissons ici les chemins d’accès aux différents répertoires du projet :\n",
    "- `PROJECT_ROOT` : Racine du projet.\n",
    "- `CLEANED_DATA_PATH` : Dossier contenant les données nettoyées.\n",
    "- `RESULTS_PATH` : Dossier où seront sauvegardés les résultats (les graphiques générés).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[2]\n",
    "CLEANED_DATA_PATH = PROJECT_ROOT / 'data' / 'cleaned'\n",
    "RESULTS_PATH = PROJECT_ROOT / 'results'\n",
    "RESULTS_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des Données Nettoyées\n",
    "\n",
    "La fonction `load_cleaned_data` charge l’ensemble des fichiers CSV nettoyés pour la catégorie **graphics_cards** provenant des plateformes *eBay*, *Flipkart* et *Ubuy*. Pour chaque fichier, elle réalise les opérations suivantes :\n",
    "\n",
    "- **Standardisation des noms de colonnes** : Conversion en minuscules et remplacement des espaces.\n",
    "- **Ajout d’une colonne `platform`** : Identification de la plateforme d’origine.\n",
    "- **Normalisation du modèle GPU** : Application de la fonction `normalize_gpu_model`.\n",
    "- **Gestion de la date de collecte** : Conversion de la colonne `collection_date` en objet date.\n",
    "  \n",
    "Les différents DataFrames sont ensuite concaténés pour constituer un DataFrame global.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cleaned_data():\n",
    "    \"\"\"Load cleaned data for graphics cards from all platforms\"\"\"\n",
    "    platforms = ['ebay', 'flipkart', 'ubuy']\n",
    "    dfs = []\n",
    "    \n",
    "    for platform in platforms:\n",
    "        path = CLEANED_DATA_PATH / platform / 'graphics_cards' / f'*.csv'\n",
    "        for file in path.parent.glob(path.name):\n",
    "            df = pd.read_csv(file)\n",
    "            \n",
    "            # Standardize column names\n",
    "            df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns]\n",
    "            \n",
    "            # Add platform identifier\n",
    "            df['platform'] = platform\n",
    "            \n",
    "            # Normalize Chipset/GPU Model\n",
    "            df['chipset/gpu_model'] = df['chipset/gpu_model'].apply(normalize_gpu_model)\n",
    "            \n",
    "            # Ensure 'collection_date' exists\n",
    "            if 'collection_date' not in df.columns:\n",
    "                print(f\"Warning: 'collection_date' column missing in {file}. Skipping file.\")\n",
    "                continue\n",
    "            \n",
    "            # Convert 'collection_date' to datetime and handle errors\n",
    "            df['collection_date'] = pd.to_datetime(df['collection_date'], errors='coerce')\n",
    "            \n",
    "            # Normalize collection_date to only include the date (ignore time)\n",
    "            df['collection_date'] = df['collection_date'].dt.date\n",
    "            \n",
    "            dfs.append(df)\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrage des Produits Selon leur Disponibilité sur Plusieurs Plateformes\n",
    "\n",
    "La fonction `filter_products_by_platforms` regroupe les produits en fonction de spécifications clés (*memory_size*, *memory_type*, *chipset/gpu_model*) afin de déterminer sur quelles plateformes chaque produit est disponible.\n",
    "\n",
    "Elle crée :\n",
    "- Une colonne `platforms` contenant la liste (triée) des plateformes pour chaque produit.\n",
    "- Une colonne `platform_count` indiquant le nombre de plateformes disponibles.\n",
    "\n",
    "Elle renvoie ensuite deux DataFrames :\n",
    "- `all_platforms` : Produits présents sur les trois plateformes.\n",
    "- `two_platforms` : Produits présents sur exactement deux plateformes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_products_by_platforms(df: pd.DataFrame):\n",
    "    \"\"\"Filter products based on their availability across platforms\"\"\"\n",
    "    # Group by key specifications\n",
    "    grouped = df.groupby(\n",
    "        ['memory_size', 'memory_type', 'chipset/gpu_model']\n",
    "    )['platform'].unique().reset_index()\n",
    "    \n",
    "    # Add a column indicating the platforms each product is available on\n",
    "    grouped['platforms'] = grouped['platform'].apply(lambda x: sorted(x))\n",
    "    grouped['platform_count'] = grouped['platforms'].apply(len)\n",
    "    \n",
    "    # Filter products available on all three platforms\n",
    "    all_platforms = grouped[grouped['platform_count'] == 3]\n",
    "    \n",
    "    # Filter products available on any two platforms\n",
    "    two_platforms = grouped[grouped['platform_count'] == 2]\n",
    "    \n",
    "    return all_platforms, two_platforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des Différences de Prix et Visualisation\n",
    "\n",
    "La fonction `analyze_price_differences` a pour objectif d'analyser les écarts de prix pour les produits disponibles sur plusieurs plateformes et de visualiser l’évolution de ces prix dans le temps.\n",
    "\n",
    "Les étapes clés sont :\n",
    "\n",
    "- **Fusion des données** : Association des produits filtrés avec les données originales pour récupérer les colonnes `collection_date` et `price`.\n",
    "- **Agrégation** : Calcul du prix moyen par jour et par plateforme.\n",
    "- **Visualisation** : Création de graphiques en barres pour chaque produit, affichant l’évolution des prix au fil des dates de collecte.\n",
    "- **Sauvegarde** : Enregistrement de chaque graphique dans le dossier des résultats, avec un nom de fichier dynamique dérivé des spécifications du produit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_price_differences(all_platforms_df: pd.DataFrame, two_platforms_df: pd.DataFrame, original_df: pd.DataFrame):\n",
    "    \"\"\"Analyze price differences and plot trends for products available on multiple platforms\"\"\"\n",
    "    category_results = RESULTS_PATH / 'graphics_cards'\n",
    "    category_results.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Combine both datasets for analysis\n",
    "    combined_df = pd.concat([all_platforms_df, two_platforms_df], ignore_index=True)\n",
    "    \n",
    "    # If no products are available on multiple platforms, skip analysis\n",
    "    if combined_df.empty:\n",
    "        print(\"No products available on multiple platforms. Skipping analysis.\")\n",
    "        return\n",
    "    \n",
    "    # Merge with the original dataframe to retain collection_date and price\n",
    "    merged_df = pd.merge(\n",
    "        original_df,\n",
    "        combined_df[['memory_size', 'memory_type', 'chipset/gpu_model']],\n",
    "        on=['memory_size', 'memory_type', 'chipset/gpu_model'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Ensure 'collection_date' exists\n",
    "    if 'collection_date' not in merged_df.columns:\n",
    "        print(\"Error: 'collection_date' column missing after merging. Skipping analysis.\")\n",
    "        return\n",
    "    \n",
    "    # Drop rows with missing collection_date\n",
    "    merged_df = merged_df.dropna(subset=['collection_date'])\n",
    "    \n",
    "    # Aggregate data by day and platform\n",
    "    df_aggregated = merged_df.groupby(\n",
    "        ['memory_size', 'memory_type', 'chipset/gpu_model', 'platform', 'collection_date']\n",
    "    )['price'].mean().reset_index()\n",
    "    \n",
    "    # Sort by date to ensure correct plotting order\n",
    "    df_aggregated = df_aggregated.sort_values('collection_date')\n",
    "    \n",
    "    # Group data for analysis\n",
    "    grouped = df_aggregated.groupby(\n",
    "        ['memory_size', 'memory_type', 'chipset/gpu_model', 'platform', 'collection_date']\n",
    "    )['price'].mean().unstack(level='platform')\n",
    "    \n",
    "    # Initialize a counter for dynamic file naming\n",
    "    product_counter = 1\n",
    "    \n",
    "    # Plot column graphs for each product\n",
    "    for product, data in grouped.groupby(level=[0, 1, 2]):\n",
    "        # Format Memory Size to remove decimals\n",
    "        memory_size = str(int(product[0])) if isinstance(product[0], (float, int)) else product[0]\n",
    "        \n",
    "        # Construct a default title using product specifications\n",
    "        product_title = f\"{memory_size}_{product[1]}_{product[2]}\"\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Plot each platform's prices as columns\n",
    "        data.plot(kind='bar', figsize=(12, 6))\n",
    "        \n",
    "        plt.title(f'Price Trends for {product_title}')\n",
    "        plt.xlabel('Collection Date')\n",
    "        plt.ylabel('Price (USD)')\n",
    "        \n",
    "        # Set x-ticks to only show dates\n",
    "        plt.xticks(range(len(data.index)), data.index.get_level_values('collection_date'), rotation=45, ha='right')\n",
    "        \n",
    "        plt.legend(title='Platform')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Sanitize the title for file naming\n",
    "        sanitized_title = (\n",
    "            \"_\".join(product_title.split())\n",
    "            .replace(\"/\", \"_\")\n",
    "            .replace(\"\\\\\", \"_\")\n",
    "            .replace(\":\", \"_\")\n",
    "            .replace(\"*\", \"_\")\n",
    "            .replace(\"?\", \"_\")\n",
    "            .replace('\"', \"_\")\n",
    "            .replace(\"<\", \"_\")\n",
    "            .replace(\">\", \"_\")\n",
    "            .replace(\"|\", \"_\")\n",
    "        )\n",
    "        \n",
    "        # Save the plot with dynamic file naming\n",
    "        file_name = f\"Product{product_counter:02d}_{sanitized_title}.png\"\n",
    "        plt.savefig(category_results / file_name)\n",
    "        plt.close()\n",
    "        \n",
    "        # Increment the counter for the next product\n",
    "        product_counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exécution Principale\n",
    "\n",
    "La dernière section orchestre l’exécution complète de l’analyse :\n",
    "\n",
    "1. **Chargement des données nettoyées** via `load_cleaned_data()`.\n",
    "2. **Filtrage des produits** disponibles sur plusieurs plateformes grâce à `filter_products_by_platforms()`.\n",
    "3. **Analyse des différences de prix** et génération des graphiques par la fonction `analyze_price_differences()`.\n",
    "\n",
    "En cas d'erreur durant le processus, un message approprié sera affiché.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"Analyzing graphics cards...\")\n",
    "        \n",
    "        # Load cleaned data for graphics cards\n",
    "        df = load_cleaned_data()\n",
    "        \n",
    "        # Par exemple, vous pouvez calculer la moyenne des prix pour les doublons ici\n",
    "        \n",
    "        # Filter products based on their availability across platforms\n",
    "        all_platforms_df, two_platforms_df = filter_products_by_platforms(df)\n",
    "        \n",
    "        # Affichage d'un résumé sur le nombre de produits identifiés\n",
    "        print(f\"Products available on all platforms: {len(all_platforms_df)}\")\n",
    "        print(f\"Products available on any two platforms: {len(two_platforms_df)}\")\n",
    "        \n",
    "        # Analyze price differences and generate plots\n",
    "        analyze_price_differences(all_platforms_df, two_platforms_df, df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing graphics cards: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
