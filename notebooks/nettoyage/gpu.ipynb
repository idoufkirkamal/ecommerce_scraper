{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Nettoyage des Données eBay - Graphics Cards\n",
    "\n",
    "Ce notebook a pour objectif de nettoyer les fichiers CSV bruts extraits d’eBay pour la catégorie **graphics_cards**.\n",
    "Les opérations réalisées incluent :\n",
    "\n",
    "- La définition des chemins des dossiers de données brutes et nettoyées.\n",
    "- L’application de plusieurs fonctions de nettoyage pour homogénéiser et corriger les données (titre, marque, prix, taille mémoire, etc.).\n",
    "- La suppression des doublons (en conservant la ligne avec le prix minimum) et le filtrage des enregistrements valides.\n",
    "- La sauvegarde des données nettoyées dans un nouveau fichier CSV.\n",
    "\n",
    "Chaque fonction utilisée est expliquée en détail.\n"
   ],
   "id": "8a900f0cbc199bda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import process\n",
    "from pathlib import Path\n"
   ],
   "id": "c7f31090645f7165"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Définition des Chemins de Données\n",
    "\n",
    "Nous utilisons la librairie `pathlib` pour définir les chemins relatifs vers :\n",
    "- Le dossier contenant les fichiers CSV bruts.\n",
    "- Le dossier dans lequel seront sauvegardés les fichiers nettoyés.\n",
    "\n",
    "Ces chemins sont définis en fonction du répertoire racine du projet.\n"
   ],
   "id": "cda3192b009d411f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Pour un notebook, vous pouvez définir BASE_DIR manuellement, par exemple :\n",
    "BASE_DIR = Path.cwd()  # Utilise le répertoire courant comme racine du projet\n",
    "\n",
    "# Si votre arborescence est différente, adaptez ces chemins :\n",
    "RAW_DATA_DIR = BASE_DIR / 'data' / 'raw' / 'ebay' / 'graphics_cards'\n",
    "CLEANED_DATA_DIR = BASE_DIR / 'data' / 'cleaned' / 'ebay' / 'graphics_cards'\n",
    "\n",
    "# Création du dossier de données nettoyées s'il n'existe pas\n",
    "CLEANED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Affichage des chemins pour vérification\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Raw data directory: {RAW_DATA_DIR}\")\n",
    "print(f\"Cleaned data directory: {CLEANED_DATA_DIR}\")\n",
    "\n",
    "# Vérifie que le dossier de données brutes existe\n",
    "if not RAW_DATA_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Raw data directory not found: {RAW_DATA_DIR}\")\n",
    "\n",
    "# Vérifie s'il y a des fichiers CSV à traiter\n",
    "files = list(RAW_DATA_DIR.glob('*.csv'))\n",
    "if not files:\n",
    "    print(f\"No CSV files found in {RAW_DATA_DIR}\")\n",
    "else:\n",
    "    print(f\"Found {len(files)} CSV files to process\")\n"
   ],
   "id": "86a866900d926891"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fonction `clean_title`\n",
    "\n",
    "La fonction `clean_title` prend en entrée une ligne (row) d'un DataFrame et réalise les opérations suivantes :\n",
    "\n",
    "1. Récupère les informations du modèle GPU et de la marque.\n",
    "2. Définit une liste de termes indésirables (ex. \"new\", \"used\", \"gpu\", \"hdmi\", etc.) à supprimer du titre.\n",
    "3. Nettoie le titre en supprimant ces termes et en éliminant les caractères spéciaux ainsi que les espaces multiples.\n",
    "4. Retourne un titre nettoyé qui privilégie l'inclusion du modèle GPU et/ou de la marque si présents dans le titre d'origine.\n"
   ],
   "id": "936be4ddb5302b2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a6ab9248718ebee9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def clean_title(row):\n",
    "    # Utilise le modèle GPU et la marque comme base\n",
    "    gpu_model = str(row[\"Chipset/GPU Model\"]).strip()\n",
    "    brand = str(row[\"Brand\"]).strip()\n",
    "\n",
    "    # Liste des termes indésirables à supprimer\n",
    "    unwanted_terms = [\n",
    "        r'\\bnew\\b', r'\\bused\\b', r'\\bgraphics\\b', r'\\bcard\\b', r'\\bgpu\\b', r'\\bvideo\\b', r'\\bhdmi\\b', r'\\bvga\\b',\n",
    "        r'\\bdvi\\b', r'\\bdisplayport\\b', r'\\bminidisplayport\\b', r'\\busb-c\\b', r'\\boc\\b', r'\\bgddr5\\b', r'\\bgddr6\\b',\n",
    "        r'\\bgddr6x\\b', r'\\b256-bit\\b', r'\\b128-bit\\b', r'\\b512mb\\b', r'\\b1gb\\b', r'\\b2gb\\b', r'\\b4gb\\b', r'\\b8gb\\b',\n",
    "        r'\\b12gb\\b', r'\\b16gb\\b', r'\\b24gb\\b', r'\\b32gb\\b', r'\\b64gb\\b', r'\\b128mb\\b', r'\\b256mb\\b', r'\\b512mb\\b',\n",
    "        r'\\b1yr\\b', r'\\bwarranty\\b', r'\\bfast\\b', r'\\bship\\b', r'\\btested\\b', r'\\bworking\\b', r'\\bnot working\\b',\n",
    "        r'\\bexcellent\\b', r'\\bcondition\\b', r'\\brefurbished\\b', r'\\bgrade\\b', r'\\bwith box\\b', r'\\bwithout box\\b',\n",
    "        r'\\bbulk\\b', r'\\boem\\b', r'\\bretail\\b', r'\\bpackage\\b', r'\\bpackaging\\b', r'\\bmodel\\b', r'\\bseries\\b',\n",
    "        r'\\bversion\\b', r'\\bgen\\b', r'\\bgen\\b', r'\\bpcie\\b', r'\\bexpress\\b', r'\\bslot\\b', r'\\bconnector\\b',\n",
    "        r'\\binterface\\b', r'\\bdual\\b', r'\\bsingle\\b', r'\\btriple\\b', r'\\bquad\\b', r'\\bhex\\b', r'\\boct\\b', r'\\bcore\\b',\n",
    "    ]\n",
    "\n",
    "    # Nettoie le titre original en minuscules\n",
    "    clean_name = row['Title'].lower()\n",
    "    for term in unwanted_terms:\n",
    "        clean_name = re.sub(term, \"\", clean_name)\n",
    "\n",
    "    # Supprime les caractères spéciaux et les espaces multiples\n",
    "    clean_name = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", clean_name).strip()\n",
    "    clean_name = re.sub(r\"\\s+\", \" \", clean_name)\n",
    "\n",
    "    # Inclut le modèle GPU et la marque si présents dans le titre\n",
    "    if gpu_model.lower() in clean_name and brand.lower() in clean_name:\n",
    "        return f\"{brand} {gpu_model}\"\n",
    "    elif gpu_model.lower() in clean_name:\n",
    "        return gpu_model\n",
    "    elif brand.lower() in clean_name:\n",
    "        return f\"{brand} {clean_name}\"\n",
    "    else:\n",
    "        return f\"{brand} {gpu_model}\" if brand != \"nan\" else gpu_model\n"
   ],
   "id": "4800217e3b4dcf8b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fonction `correct_brands`\n",
    "\n",
    "Cette fonction corrige les noms de marque en utilisant un algorithme de correspondance floue (fuzzy matching) grâce à la librairie `fuzzywuzzy`.\n",
    "\n",
    "Pour chaque marque présente dans la colonne `Brand` du DataFrame, la fonction :\n",
    "- Compare la valeur actuelle avec la liste des marques uniques.\n",
    "- Si le score de correspondance est supérieur à 85, la marque est remplacée par la correspondance trouvée.\n",
    "- Retourne le DataFrame avec la colonne `Brand` mise à jour.\n"
   ],
   "id": "41b2813a30bc3e59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def correct_brands(df):\n",
    "    brands = df['Brand'].dropna().unique().tolist()\n",
    "    brand_mapping = {}\n",
    "    for brand in df['Brand']:\n",
    "        if pd.isna(brand):\n",
    "            continue\n",
    "        match, score = process.extractOne(brand, brands)\n",
    "        brand_mapping[brand] = match if score > 85 else brand\n",
    "    df['Brand'] = df['Brand'].replace(brand_mapping)\n",
    "    return df\n"
   ],
   "id": "192739587e875dfb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fonction `clean_price`\n",
    "\n",
    "La fonction `clean_price` a pour but de normaliser les valeurs de prix en :\n",
    "- Supprimant tous les caractères non numériques (sauf la virgule et le point).\n",
    "- Gérant les formats décimaux (par exemple, en remplaçant correctement les séparateurs).\n",
    "- Convertissant la chaîne nettoyée en type `float`.\n",
    "\n",
    "Si le prix est vide ou non défini, la fonction retourne `None`.\n"
   ],
   "id": "883a4017529ea786"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def clean_price(price):\n",
    "    if isinstance(price, str):\n",
    "        price = re.sub(r'[^\\d.,]', '', price)\n",
    "        if ',' in price and '.' in price:\n",
    "            if price.index(',') < price.index('.'):\n",
    "                price = price.replace(',', '')\n",
    "            else:\n",
    "                price = price.replace('.', '').replace(',', '.')\n",
    "        else:\n",
    "            price = price.replace(',', '.')\n",
    "    return float(price) if price else None\n"
   ],
   "id": "ea216e1d3361eca5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fonction `convert_to_gb`\n",
    "\n",
    "Cette fonction normalise les valeurs de taille mémoire en :\n",
    "- Convertissant les valeurs en MB en GB (en divisant par 1024).\n",
    "- Extrayant la partie numérique d'une chaîne contenant la taille mémoire.\n",
    "- Retourne la taille mémoire sous forme de `float` ou `None` si la valeur est absente.\n"
   ],
   "id": "22554319d577890b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def convert_to_gb(value):\n",
    "    if pd.isna(value) or value.strip() == '':\n",
    "        return None\n",
    "    try:\n",
    "        if 'MB' in value.upper():\n",
    "            return float(value.upper().replace('MB', '').strip()) / 1024\n",
    "        return float(re.sub(r'[^\\d.]', '', value))\n",
    "    except ValueError"
   ],
   "id": "fe83bb9dc36ba9e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    ## Fonctions de Remplissage des Valeurs Manquantes\n",
    "\n",
    "Deux fonctions sont définies pour traiter les valeurs manquantes :\n",
    "- **fill_with_median_or_default** : Remplit les valeurs manquantes d'une série avec la médiane, ou avec 0 si la série est vide.\n",
    "- **fill_with_mode** : Remplit les valeurs manquantes d'une série avec la valeur la plus fréquente (mode).\n"
   ],
   "id": "790624aa3af1aa65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fill_with_median_or_default(series):\n",
    "    if series.notna().any():\n",
    "        return series.fillna(series.median())\n",
    "    else:\n",
    "        return series.fillna(0)\n",
    "\n",
    "def fill_with_mode(series):\n",
    "    if series.notna().any():\n",
    "        return series.fillna(series.mode()[0])\n",
    "    else:\n",
    "        return series\n"
   ],
   "id": "dbef9466bc607d6d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fonction `remove_duplicates_with_min_price`\n",
    "\n",
    "Cette fonction supprime les doublons du DataFrame en gardant pour chaque groupe (défini par `Brand`, `Memory Size`, `Memory Type`, `Chipset/GPU Model`) la ligne ayant le prix minimum.\n"
   ],
   "id": "8cdbb64147e0c9ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d81943d2e7ee8ab6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def remove_duplicates_with_min_price(df):\n",
    "    columns_for_duplicates = ['Brand', 'Memory Size', 'Memory Type', 'Chipset/GPU Model']\n",
    "    idx_min_price = df.groupby(columns_for_duplicates)['Price'].idxmin()\n",
    "    return df.loc[idx_min_price].reset_index(drop=True)\n"
   ],
   "id": "854d6f5d92a18604"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fonction `drop_unnecessary_columns`\n",
    "\n",
    "Cette fonction conserve uniquement les colonnes essentielles pour l’analyse finale, à savoir :\n",
    "- `title`, `Price`, `Brand`, `Memory Size`, `Memory Type`, `Chipset/GPU Model`, `Connectors`, et `Collection Date`.\n"
   ],
   "id": "8604e5a9981cfac0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def drop_unnecessary_columns(df):\n",
    "    columns_to_keep = ['title', 'Price', 'Brand', 'Memory Size', 'Memory Type', 'Chipset/GPU Model', 'Connectors', 'Collection Date']\n",
    "    existing_columns = [col for col in columns_to_keep if col in df.columns]\n",
    "    return df[existing_columns]\n"
   ],
   "id": "c0313884493a6c20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Traitement Global des Fichiers CSV\n",
    "\n",
    "Dans cette partie, nous parcourons tous les fichiers CSV du dossier de données brutes et appliquons l’ensemble des fonctions de nettoyage :\n",
    "\n",
    "1. Chargement de chaque fichier CSV dans un DataFrame.\n",
    "2. Application de la fonction `clean_title` pour créer une colonne `Cleaned Title`.\n",
    "3. Correction des marques via `correct_brands`.\n",
    "4. Normalisation des colonnes `Price` et `Memory Size` avec les fonctions `clean_price` et `convert_to_gb`.\n",
    "5. Remplissage des valeurs manquantes pour `Memory Size`, `Price`, `Memory Type` et `Connectors` par regroupement sur `Chipset/GPU Model`.\n",
    "6. Suppression des doublons en conservant le produit au prix minimum.\n",
    "7. Filtrage des enregistrements avec des valeurs de `Price` et `Memory Size` valides.\n",
    "8. Suppression de la colonne d’origine `Title` et renommage de `Cleaned Title` en `title`.\n",
    "9. Conservation uniquement des colonnes nécessaires.\n",
    "10. Sauvegarde du DataFrame nettoyé dans un nouveau fichier CSV dans le dossier de données nettoyées.\n"
   ],
   "id": "2ca53d580038e8c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "try:\n",
    "    for file in RAW_DATA_DIR.glob('*.csv'):\n",
    "        print(f\"Processing file: {file}\")\n",
    "        df = pd.read_csv(file)\n",
    "        print(f\"Loaded {len(df)} rows from {file.name}\")\n",
    "        print(f\"Columns in the file: {df.columns.tolist()}\")\n",
    "\n",
    "        # Application des fonctions de nettoyage\n",
    "        df['Cleaned Title'] = df.apply(clean_title, axis=1)\n",
    "        df = correct_brands(df)\n",
    "        df['Price'] = df['Price'].apply(clean_price)\n",
    "        df['Memory Size'] = df['Memory Size'].astype(str).apply(convert_to_gb)\n",
    "        df['Memory Size'] = df.groupby('Chipset/GPU Model')['Memory Size'].transform(fill_with_median_or_default)\n",
    "        df['Price'] = df.groupby('Chipset/GPU Model')['Price'].transform(fill_with_median_or_default)\n",
    "        df['Memory Type'] = df.groupby('Chipset/GPU Model')['Memory Type'].transform(fill_with_mode)\n",
    "        df['Connectors'] = df.groupby('Chipset/GPU Model')['Connectors'].transform(fill_with_mode)\n",
    "        df = remove_duplicates_with_min_price(df)\n",
    "\n",
    "        # Validation des données (prix et taille mémoire strictement positifs)\n",
    "        df = df[(df['Price'] > 0) & (df['Memory Size'] > 0.1)]\n",
    "\n",
    "        # Suppression de la colonne d'origine 'Title'\n",
    "        if 'Title' in df.columns:\n",
    "            df.drop(columns=['Title'], inplace=True)\n",
    "\n",
    "        # Renommage de 'Cleaned Title' en 'title'\n",
    "\n",
    "\n",
    "        # Conservation uniquement des colonnes utiles\n",
    "        df = drop_unnecessary_columns(df)\n",
    "\n",
    "        # Sauvegarde du DataFrame nettoyé dans un nouveau fichier CSV\n",
    "        output_filename = CLEANED_DATA_DIR / f\"{file.stem}_cleaned.csv\"\n",
    "        df.to_csv(output_filename, index=False)\n",
    "        print(f\"Cleaned data saved to {output_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ],
   "id": "a1fbcf4eaaade8e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce notebook a permis de traiter et de nettoyer les fichiers CSV bruts extraits d’eBay pour la catégorie **graphics_cards**.\n",
    "Les principales opérations effectuées sont :\n",
    "- Nettoyage et homogénéisation des titres.\n",
    "- Correction des noms de marques grâce à une correspondance floue.\n",
    "- Normalisation des prix et de la taille mémoire.\n",
    "- Remplissage des valeurs manquantes, suppression des doublons et filtrage des enregistrements non valides.\n",
    "- Sauvegarde des données nettoyées dans un nouveau dossier.\n",
    "\n",
    "Vous pouvez désormais utiliser ces données nettoyées pour vos analyses ou visualisations ultérieures.\n",
    "\n",
    "Bonne utilisation !\n"
   ],
   "id": "b8a1942171d4bc11"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
